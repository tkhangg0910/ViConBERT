{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7befde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ B·∫Øt ƒë·∫ßu ki·ªÉm tra...\n",
      "‚úó L·ªói khi ƒë·ªçc file JSON: [Errno 2] No such file or directory: 'data.json'\n",
      "‚úó L·ªói khi ƒë·ªçc file CSV: [Errno 2] No such file or directory: 'words.csv'\n",
      "‚ùå Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n file.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import re\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "class WordChecker:\n",
    "    def __init__(self, json_file_path: str, csv_file_path: str):\n",
    "        \"\"\"\n",
    "        Kh·ªüi t·∫°o WordChecker\n",
    "        \n",
    "        Args:\n",
    "            json_file_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file JSON\n",
    "            csv_file_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file CSV\n",
    "        \"\"\"\n",
    "        self.json_file_path = json_file_path\n",
    "        self.csv_file_path = csv_file_path\n",
    "        self.json_data = {}\n",
    "        self.csv_data = {}\n",
    "        \n",
    "    def load_json_data(self) -> Dict:\n",
    "        \"\"\"T·∫£i d·ªØ li·ªáu t·ª´ file JSON\"\"\"\n",
    "        try:\n",
    "            with open(self.json_file_path, 'r', encoding='utf-8') as f:\n",
    "                self.json_data = json.load(f)\n",
    "            print(f\"‚úì ƒê√£ t·∫£i th√†nh c√¥ng {len(self.json_data)} entries t·ª´ file JSON\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó L·ªói khi ƒë·ªçc file JSON: {e}\")\n",
    "        return self.json_data\n",
    "    \n",
    "    def load_csv_data(self) -> Dict:\n",
    "        \"\"\"T·∫£i d·ªØ li·ªáu t·ª´ file CSV\"\"\"\n",
    "        try:\n",
    "            with open(self.csv_file_path, 'r', encoding='utf-8') as f:\n",
    "                csv_reader = csv.DictReader(f)\n",
    "                for row in csv_reader:\n",
    "                    word_id = row['word_id']\n",
    "                    self.csv_data[word_id] = {\n",
    "                        'word': row['word'],\n",
    "                        'synset_id': row['synset_id'],\n",
    "                        'pos': row['pos'],\n",
    "                        'gloss': row['gloss']\n",
    "                    }\n",
    "            print(f\"‚úì ƒê√£ t·∫£i th√†nh c√¥ng {len(self.csv_data)} t·ª´ t·ª´ file CSV\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó L·ªói khi ƒë·ªçc file CSV: {e}\")\n",
    "        return self.csv_data\n",
    "    \n",
    "    def check_word_in_sentences(self, word: str, sentences: List[str]) -> Tuple[bool, List[str]]:\n",
    "        \"\"\"\n",
    "        Ki·ªÉm tra xem t·ª´ c√≥ xu·∫•t hi·ªán trong danh s√°ch c√¢u kh√¥ng\n",
    "        \n",
    "        Args:\n",
    "            word: T·ª´ c·∫ßn ki·ªÉm tra\n",
    "            sentences: Danh s√°ch c√°c c√¢u\n",
    "            \n",
    "        Returns:\n",
    "            Tuple(c√≥ xu·∫•t hi·ªán hay kh√¥ng, danh s√°ch c√¢u ch·ª©a t·ª´ ƒë√≥)\n",
    "        \"\"\"\n",
    "        found_sentences = []\n",
    "        \n",
    "        # T·∫°o pattern ƒë·ªÉ t√¨m t·ª´ (word boundary ƒë·ªÉ tr√°nh t√¨m t·ª´ con)\n",
    "        pattern = r'\\b' + re.escape(word) + r'\\b'\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            if re.search(pattern, sentence, re.IGNORECASE):\n",
    "                found_sentences.append(sentence)\n",
    "        \n",
    "        return len(found_sentences) > 0, found_sentences\n",
    "    \n",
    "    def check_all_words(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Ki·ªÉm tra t·∫•t c·∫£ c√°c t·ª´ trong CSV c√≥ xu·∫•t hi·ªán trong JSON t∆∞∆°ng ·ª©ng kh√¥ng\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary ch·ª©a k·∫øt qu·∫£ ki·ªÉm tra\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            'found': [],\n",
    "            'not_found': [],\n",
    "            'missing_word_id': []\n",
    "        }\n",
    "        \n",
    "        for word_id, word_info in self.csv_data.items():\n",
    "            word = word_info['word']\n",
    "            \n",
    "            # Ki·ªÉm tra xem word_id c√≥ t·ªìn t·∫°i trong JSON kh√¥ng\n",
    "            if word_id not in self.json_data:\n",
    "                results['missing_word_id'].append({\n",
    "                    'word_id': word_id,\n",
    "                    'word': word,\n",
    "                    'reason': f'word_id {word_id} kh√¥ng t·ªìn t·∫°i trong file JSON'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # L·∫•y danh s√°ch c√¢u t·ª´ JSON\n",
    "            sentences = self.json_data[word_id]\n",
    "            \n",
    "            # Ki·ªÉm tra t·ª´ c√≥ xu·∫•t hi·ªán trong c√¢u kh√¥ng\n",
    "            found, found_sentences = self.check_word_in_sentences(word, sentences)\n",
    "            \n",
    "            if found:\n",
    "                results['found'].append({\n",
    "                    'word_id': word_id,\n",
    "                    'word': word,\n",
    "                    'total_sentences': len(sentences),\n",
    "                    'sentences_with_word': len(found_sentences),\n",
    "                    'found_sentences': found_sentences\n",
    "                })\n",
    "            else:\n",
    "                results['not_found'].append({\n",
    "                    'word_id': word_id,\n",
    "                    'word': word,\n",
    "                    'sentences': sentences\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def print_summary(self, results: Dict):\n",
    "        \"\"\"In t√≥m t·∫Øt k·∫øt qu·∫£\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"                    T√ìM T·∫ÆT K·∫æT QU·∫¢\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        total_words = len(self.csv_data)\n",
    "        found_count = len(results['found'])\n",
    "        not_found_count = len(results['not_found'])\n",
    "        missing_id_count = len(results['missing_word_id'])\n",
    "        \n",
    "        print(f\"üìä T·ªïng s·ªë t·ª´ c·∫ßn ki·ªÉm tra: {total_words}\")\n",
    "        print(f\"‚úÖ S·ªë t·ª´ t√¨m th·∫•y trong c√¢u: {found_count}\")\n",
    "        print(f\"‚ùå S·ªë t·ª´ KH√îNG t√¨m th·∫•y trong c√¢u: {not_found_count}\")\n",
    "        print(f\"‚ö†Ô∏è  S·ªë word_id kh√¥ng t·ªìn t·∫°i trong JSON: {missing_id_count}\")\n",
    "        print(f\"üìà T·ª∑ l·ªá t√¨m th·∫•y: {found_count/max(total_words-missing_id_count, 1)*100:.1f}%\")\n",
    "    \n",
    "    def print_detailed_results(self, results: Dict, show_found: bool = True, show_not_found: bool = True):\n",
    "        \"\"\"In k·∫øt qu·∫£ chi ti·∫øt\"\"\"\n",
    "        \n",
    "        if show_found and results['found']:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"‚úÖ C√ÅC T·ª™ T√åM TH·∫§Y TRONG C√ÇU\")\n",
    "            print(\"=\"*60)\n",
    "            for item in results['found']:\n",
    "                print(f\"\\nüîç Word ID: {item['word_id']} | T·ª´: '{item['word']}'\")\n",
    "                print(f\"   üìù T·ªïng s·ªë c√¢u: {item['total_sentences']}\")\n",
    "                print(f\"   ‚ú® S·ªë c√¢u ch·ª©a t·ª´: {item['sentences_with_word']}\")\n",
    "                print(\"   üìÑ C√°c c√¢u ch·ª©a t·ª´:\")\n",
    "                for i, sentence in enumerate(item['found_sentences'], 1):\n",
    "                    print(f\"      {i}. {sentence}\")\n",
    "        \n",
    "        if show_not_found and results['not_found']:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"‚ùå C√ÅC T·ª™ KH√îNG T√åM TH·∫§Y TRONG C√ÇU\")\n",
    "            print(\"=\"*60)\n",
    "            for item in results['not_found']:\n",
    "                print(f\"\\nüîç Word ID: {item['word_id']} | T·ª´: '{item['word']}'\")\n",
    "                print(\"   üìÑ C√°c c√¢u trong JSON:\")\n",
    "                for i, sentence in enumerate(item['sentences'], 1):\n",
    "                    print(f\"      {i}. {sentence}\")\n",
    "        \n",
    "        if results['missing_word_id']:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"‚ö†Ô∏è  C√ÅC WORD_ID KH√îNG T·ªíN T·∫†I TRONG JSON\")\n",
    "            print(\"=\"*60)\n",
    "            for item in results['missing_word_id']:\n",
    "                print(f\"   Word ID: {item['word_id']} | T·ª´: '{item['word']}'\")\n",
    "                print(f\"   L√Ω do: {item['reason']}\")\n",
    "    \n",
    "    def run_check(self, show_details: bool = True, show_found: bool = True, show_not_found: bool = True):\n",
    "        \"\"\"\n",
    "        Ch·∫°y ki·ªÉm tra ho√†n ch·ªânh\n",
    "        \n",
    "        Args:\n",
    "            show_details: Hi·ªÉn th·ªã k·∫øt qu·∫£ chi ti·∫øt\n",
    "            show_found: Hi·ªÉn th·ªã c√°c t·ª´ t√¨m th·∫•y\n",
    "            show_not_found: Hi·ªÉn th·ªã c√°c t·ª´ kh√¥ng t√¨m th·∫•y\n",
    "        \"\"\"\n",
    "        print(\"üöÄ B·∫Øt ƒë·∫ßu ki·ªÉm tra...\")\n",
    "        \n",
    "        # T·∫£i d·ªØ li·ªáu\n",
    "        self.load_json_data()\n",
    "        self.load_csv_data()\n",
    "        \n",
    "        if not self.json_data or not self.csv_data:\n",
    "            print(\"‚ùå Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n file.\")\n",
    "            return None\n",
    "        \n",
    "        # Th·ª±c hi·ªán ki·ªÉm tra\n",
    "        print(\"\\nüîç ƒêang ki·ªÉm tra...\")\n",
    "        results = self.check_all_words()\n",
    "        \n",
    "        # In k·∫øt qu·∫£\n",
    "        self.print_summary(results)\n",
    "        \n",
    "        if show_details:\n",
    "            self.print_detailed_results(results, show_found, show_not_found)\n",
    "        \n",
    "        return results\n",
    "\n",
    "# H√†m s·ª≠ d·ª•ng\n",
    "def main():\n",
    "    \"\"\"H√†m ch√≠nh ƒë·ªÉ ch·∫°y tool\"\"\"\n",
    "    # ƒê∆∞·ªùng d·∫´n t·ªõi c√°c file\n",
    "    json_file = \"pseudo_sent.json\"  # Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n n√†y\n",
    "    csv_file = \"word_synsets_with_pos_with_gloss.csv\"   # Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n n√†y\n",
    "    \n",
    "    # T·∫°o v√† ch·∫°y checker\n",
    "    checker = WordChecker(json_file, csv_file)\n",
    "    results = checker.run_check(\n",
    "        show_details=True,      # Hi·ªÉn th·ªã chi ti·∫øt\n",
    "        show_found=True,        # Hi·ªÉn th·ªã t·ª´ t√¨m th·∫•y\n",
    "        show_not_found=True     # Hi·ªÉn th·ªã t·ª´ kh√¥ng t√¨m th·∫•y\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ch·∫°y tool\n",
    "    main()\n",
    "    \n",
    "    # Ho·∫∑c b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng nh∆∞ sau:\n",
    "    # checker = WordChecker(\"path_to_json.json\", \"path_to_csv.csv\")\n",
    "    # results = checker.run_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c5af920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ho√†n th√†nh! ƒê√£ t√¨m th·∫•y 15165 t·ª´ c√≥ v·∫•n ƒë·ªÅ.\n",
      "K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o missing_words_full.csv v·ªõi ƒë·∫ßy ƒë·ªß c√°c c·ªôt.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu t·ª´ file JSON\n",
    "json_file_path = \"pseudo_sent.json\"\n",
    "with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV\n",
    "csv_file_path = \"word_synsets_with_pos_with_gloss.csv\"\n",
    "csv_rows = []\n",
    "word_dict = {}\n",
    "\n",
    "with open(csv_file_path, 'r', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    fieldnames = reader.fieldnames  # L∆∞u t√™n c√°c c·ªôt\n",
    "    \n",
    "    for row in reader:\n",
    "        csv_rows.append(row)\n",
    "        word_dict[row['word_id']] = row['word']  # L∆∞u √°nh x·∫° word_id -> word\n",
    "\n",
    "# T√¨m c√°c word_id kh√¥ng c√≥ trong √≠t nh·∫•t m·ªôt c√¢u\n",
    "problematic_ids = set()\n",
    "\n",
    "for word_id, sentences in json_data.items():\n",
    "    if word_id in word_dict:\n",
    "        target_word = word_dict[word_id]\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            # Ki·ªÉm tra t·ª´ kh√¥ng t·ªìn t·∫°i trong c√¢u (kh√¥ng ph√¢n bi·ªát hoa th∆∞·ªùng)\n",
    "            if target_word.lower() not in sentence.lower():\n",
    "                problematic_ids.add(word_id)\n",
    "                break  # Ch·ªâ c·∫ßn 1 c√¢u kh√¥ng c√≥ t·ª´ l√† ƒë·ªß\n",
    "\n",
    "# L·ªçc c√°c d√≤ng CSV c√≥ word_id b·ªã l·ªói\n",
    "problematic_rows = [row for row in csv_rows if row['word_id'] in problematic_ids]\n",
    "\n",
    "# Ghi k·∫øt qu·∫£ ra file CSV (v·ªõi t·∫•t c·∫£ c√°c c·ªôt)\n",
    "output_file = \"missing_words_full.csv\"\n",
    "with open(output_file, 'w', encoding='utf-8', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(problematic_rows)\n",
    "\n",
    "print(f\"Ho√†n th√†nh! ƒê√£ t√¨m th·∫•y {len(problematic_ids)} t·ª´ c√≥ v·∫•n ƒë·ªÅ.\")\n",
    "print(f\"K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o {output_file} v·ªõi ƒë·∫ßy ƒë·ªß c√°c c·ªôt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7047b2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fa5b96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
