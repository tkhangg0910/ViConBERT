project:
  name: "vietnamese_wordnet_embedding"
  language: "vi"
  seed: 42

stage_name: "contrastive_pretraining"
base_model: "vinai/phobert-base"
base_model_cache_dir: "embeddings/phobert-base"
output_dir: "./checkpoints/phobert_base"

data:
  train_path: "data/processed/stage1_pseudo_sents/train_data_v2.json"
  valid_path: "data/processed/stage1_pseudo_sents/valid_data_v2.json"
  emd_path: "data/processed/stage1_pseudo_sents/gloss_embeddings.pt"
  num_workers: 16

model:  
  temperature: 0.3
  hidden_dim: 512
  dropout: 0.3
  out_dim: 256
  num_layers: 1
  context_window_size: 3
  use_proj: False
  polym: 8
  encoder_type: attentive

training:
  ckpt_interval: 10
  shuffle: False
  batch_size: 1
  epochs: 100
  early_stopping_patience: 5
  save_steps: 1000
  optimizer:
    name: "adamw"
    lr_base: 2e-4        
    lr_custom: 5e-4 
    weight_decay: 0.01
    eps: 1e-6
    betas: [0.9, 0.999]
